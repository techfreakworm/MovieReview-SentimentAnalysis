{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysisUsingMLP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/techfreakworm/MovieReview-SentimentAnalysis/blob/tensorflow-dnn/SentimentAnalysisUsingMLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "hcr6aF8TQUpE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from keras.datasets import imdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kMFJWxqFRMha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# vocabulary_size = 5000\n",
        "# (X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n",
        "# print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NcddUUWQRbEN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# type(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hoKj7B4aRm7V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# X_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OZqzTmwNXs9d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # Install the latest Tensorflow version.\n",
        "# !pip install --quiet \"tensorflow>=1.7\"\n",
        "# # Install TF-Hub.\n",
        "# !pip install -q tensorflow-hub\n",
        "# !pip install -q seaborn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ELWloHROIJZa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !ls sample_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8AvRWzUHX0iP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9eG13KuaJsvZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.logging.set_verbosity(tf.logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hAevZokFRtTY",
        "colab_type": "code",
        "outputId": "5e59dfd1-a69a-4c4e-97d0-151ea63464ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# Load all files from a directory in a DataFrame.\n",
        "def load_directory_data(directory):\n",
        "  data = {}\n",
        "  data[\"sentence\"] = []\n",
        "  data[\"sentiment\"] = []\n",
        "  for file_path in os.listdir(directory):\n",
        "    with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
        "      data[\"sentence\"].append(f.read())\n",
        "      data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
        "  return pd.DataFrame.from_dict(data)\n",
        "\n",
        "# Merge positive and negative examples, add a polarity column and shuffle.\n",
        "def load_dataset(directory):\n",
        "  pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
        "  neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
        "  pos_df[\"polarity\"] = 1\n",
        "  neg_df[\"polarity\"] = 0\n",
        "  return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Download and process the dataset files.\n",
        "def download_and_load_datasets(force_download=False):\n",
        "  dataset = tf.keras.utils.get_file(\n",
        "      fname=\"aclImdb.tar.gz\", \n",
        "      origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
        "      extract=True)\n",
        "  \n",
        "  train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                       \"aclImdb\", \"train\"))\n",
        "  test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                      \"aclImdb\", \"test\"))\n",
        "  \n",
        "  return train_df, test_df\n",
        "\n",
        "# Reduce logging output.\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "train_df, test_df = download_and_load_datasets()\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I saw the 10p.m. showing and I must say that t...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"Gespenster\" Question of to be cool in the Ger...</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Charming doesn't even begin to describe \"Savin...</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Its not the cast. A finer group of actors, you...</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I just read a review defending this film becau...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence sentiment  polarity\n",
              "0  I saw the 10p.m. showing and I must say that t...         1         0\n",
              "1  \"Gespenster\" Question of to be cool in the Ger...         8         1\n",
              "2  Charming doesn't even begin to describe \"Savin...         8         1\n",
              "3  Its not the cast. A finer group of actors, you...         4         0\n",
              "4  I just read a review defending this film becau...         2         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "x3foWxnhXby3",
        "colab_type": "code",
        "outputId": "806c43ab-027a-4f65-b2f1-80e7691bb3e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25000 entries, 0 to 24999\n",
            "Data columns (total 3 columns):\n",
            "sentence     25000 non-null object\n",
            "sentiment    25000 non-null object\n",
            "polarity     25000 non-null int64\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 586.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yFtA7O3dYPxE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training input on the whole training set with no limit on training epochs.\n",
        "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    train_df, train_df[\"polarity\"], num_epochs=None, shuffle=True)\n",
        "\n",
        "# Prediction on the whole training set.\n",
        "predict_train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    train_df, train_df[\"polarity\"], shuffle=False)\n",
        "# Prediction on the test set.\n",
        "predict_test_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    test_df, test_df[\"polarity\"], shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gO4PMygfYfEe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedded_text_feature_column = hub.text_embedding_column(\n",
        "    key=\"sentence\", \n",
        "    module_spec=\"https://tfhub.dev/google/nnlm-en-dim128/1\",\n",
        "    trainable=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "brpYYoPtKBas",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Training config added later (required for saving estimator)\n",
        "# training_config = tf.estimator.RunConfig(\n",
        "#         model_dir=FLAGS.model_dir,\n",
        "#         save_summary_steps=100,\n",
        "#         save_checkpoints_steps=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "56IcWkE2ZI0R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "estimator = tf.estimator.DNNClassifier(\n",
        "#     config=training_config,\n",
        "    hidden_units=[500, 1000, 1000, 500, 100],\n",
        "    feature_columns=[embedded_text_feature_column],\n",
        "    n_classes=2,\n",
        "    optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "khfjzhoXZZtT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training for 1,000 steps means 128,000 training examples with the default\n",
        "# batch size. This is roughly equivalent to 5 epochs since the training dataset\n",
        "# contains 25,000 examples.\n",
        "estimator.train(input_fn=train_input_fn, steps=1000);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ev0vYVg7ZeEM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_eval_result = estimator.evaluate(input_fn=predict_train_input_fn)\n",
        "test_eval_result = estimator.evaluate(input_fn=predict_test_input_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UI7AKiRdZpGc",
        "colab_type": "code",
        "outputId": "246ea0f7-3e0a-4726-cb14-6d4fe4bd72ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Training set accuracy: {accuracy}\".format(**train_eval_result))\n",
        "print(\"Test set accuracy: {accuracy}\".format(**test_eval_result))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set accuracy: 0.9721199870109558\n",
            "Test set accuracy: 0.868399977684021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yxNiQeDaDTxF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# For Server Input function (Defines how inputs would be handled when the inputs are exported and served)"
      ]
    },
    {
      "metadata": {
        "id": "t7N5X8EbDeGc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def serving_input_receiver_fn():\n",
        "#     \"\"\"\n",
        "#     This is used to define inputs to serve the model.\n",
        "#     :return: ServingInputReciever\n",
        "#     \"\"\"\n",
        "#     receiver_tensors = {\n",
        "#         'sentence': tf.placeholder(tf.string, [None, 1])\n",
        "#     }\n",
        "\n",
        "#     # Convert give inputs to adjust to the model.\n",
        "#     features = {\n",
        "#         'sentence': tf.concat([\n",
        "#             receiver_tensors['sentence']\n",
        "#         ], axis=1)\n",
        "#     }\n",
        "#     return tf.estimator.export.ServingInputReceiver(receiver_tensors=receiver_tensors,\n",
        "#                                                     features=features)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RIvjxurx2jBJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# feature_spec = tf.feature_column.make_parse_example_spec(embedded_text_feature_column)\n",
        "# export_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hYTEJE11r1q9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# embed = hub.Module(\"https://tfhub.dev/google/nnlm-en-dim128/1\")\n",
        "# embeddings = embed([\"cat is on the mat\", \"dog is in the fog\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v-OJuXgsZtvP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentence_array = np.array(['My friends criticised this movie a lot, i thought this would be a complete shit show, and they were actually right. This movie didn\\'t have good concept, no clear storyline and not even a good ending'])\n",
        "features = {\n",
        "'sentence': sentence_array\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s3DouPxcr36e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction_function = tf.estimator.inputs.numpy_input_fn(x=features, batch_size=len(features), shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2HQZaN9SvDvh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = list(estimator.predict(input_fn=prediction_function))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u_iRDzcmvUzs",
        "colab_type": "code",
        "outputId": "fadf6785-5745-48e7-8de8-49f37bafc80e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'class_ids': array([0]),\n",
              "  'classes': array([b'0'], dtype=object),\n",
              "  'logistic': array([0.39732113], dtype=float32),\n",
              "  'logits': array([-0.41663954], dtype=float32),\n",
              "  'probabilities': array([0.60267884, 0.39732116], dtype=float32)}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "JpJIwaG5vbYN",
        "colab_type": "code",
        "outputId": "4568e588-3423-4d3c-922e-30de2ec20fa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "predictions[0]['class_ids'][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "c-6p8FpJNopf",
        "colab_type": "code",
        "outputId": "c4202081-0182-484d-dac5-40359f13c0ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mEC5xN3gwsVx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BbYoK_l0wudp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}